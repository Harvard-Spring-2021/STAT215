knn = train(x = scaled_train_df,
y = train_outcome$phenotype,
method = "knn",
metric = metric,
trControl = control,
tuneGrid = expand.grid(k=seq(1,10,1)))
# Logistic Regression
# https://stackoverflow.com/questions/39550118/cross-validation-function-for-logistic-regression-in-r
lr = train(x = train_df,
y = train_outcome$phenotype,
method = "glm",
family = binomial(),
metric = metric,
trControl = control)
# Ridge Regression
ridge = train(x = train_df,
y = train_outcome$phenotype,
method = "glmnet",
trControl = control,
tuneGrid = expand.grid(alpha = 0, lambda = lambda))
# LASSO
lasso = train(x = train_df,
y = train_outcome$phenotype,
method = "glmnet",
trControl = control,
tuneGrid = expand.grid(alpha = 1, lambda = lambda))
# ElasticNet
lasso = train(x = train_df,
y = train_outcome$phenotype,
method = "glmnet",
trControl = control,
tuneLength = 10)
# Random Forest
rf = train(x = train_df,
y = train_outcome$phenotype,
method = "rf",
trControl = control,
tuneGrid = expand.grid(mtry=seq(1,15,1)))
# SVM
svm = train(x = train_df,
y = train_outcome$phenotype,
method = "svmLinear",
trControl = control,
tuneGrid = expand.grid(C=c(0.01, 0.1, 1, 10)))
knn
summary(knn)
summary(metrix)
knn$metric
lr
View(knn)
knn@results
knn[["results"]]
knn[["results"]]
knn[["results"]]```
lr[["results"]]
### Your code here
knn[["results"]]
lr[["results"]]
ridge[["results"]]
lasso[["results"]]
elastic[["results"]]
### Your code here
set.seed(215)
# filter for the 25 top PCs
train_df = data.frame(res.pca$x[,c(1:25)])
train_outcome = data.frame(sample = rownames(train_df))
train_outcome = merge(train_outcome, train_label, by="sample")
train_outcome$phenotype = as.factor(train_outcome$phenotype)
# preProcessing for algorithms using Euclidean distances
scaled_train_df = predict(preProcess(train_df, method = c("center", "scale")),
train_df)
# fixed parameters
control = trainControl(method = "cv",
number = 5,
savePredictions = TRUE,
classProbs = TRUE)
metric = "Accuracy"
lambda = 10^seq(-3, 3, length = 100)
# KNN
knn = train(x = scaled_train_df,
y = train_outcome$phenotype,
method = "knn",
metric = metric,
trControl = control,
tuneGrid = expand.grid(k=seq(1,10,1)))
# Logistic Regression
# https://stackoverflow.com/questions/39550118/cross-validation-function-for-logistic-regression-in-r
lr = train(x = train_df,
y = train_outcome$phenotype,
method = "glm",
family = binomial(),
metric = metric,
trControl = control)
# Ridge Regression
ridge = train(x = train_df,
y = train_outcome$phenotype,
method = "glmnet",
trControl = control,
tuneGrid = expand.grid(alpha = 0, lambda = lambda))
# LASSO
lasso = train(x = train_df,
y = train_outcome$phenotype,
method = "glmnet",
trControl = control,
tuneGrid = expand.grid(alpha = 1, lambda = lambda))
# ElasticNet
elastic = train(x = train_df,
y = train_outcome$phenotype,
method = "glmnet",
trControl = control,
tuneLength = 10)
# Random Forest
rf = train(x = train_df,
y = train_outcome$phenotype,
method = "rf",
trControl = control,
tuneGrid = expand.grid(mtry=seq(1,15,1)))
# SVM
svm = train(x = train_df,
y = train_outcome$phenotype,
method = "svmLinear",
trControl = control,
tuneGrid = expand.grid(C=c(0.01, 0.1, 1, 10)))
### Your code here
knn[["results"]]
lr[["results"]]
ridge[["results"]]
lasso[["results"]]
elastic[["results"]]
rf[["results"]]
svm[["results"]]
# Perform PCA of the samples using log2 transformed TPM values & making scree plot
res.pca = prcomp(logTPM.df, scale = TRUE)
pca.var.per = round(res.pca$sdev^2/sum(res.pca$sdev^2)*100,1)
fviz_eig(res.pca, addlabels=TRUE, ylim=c(0,100),
geom=c("bar", "line"), barfill="gold",
barcolor="grey", linecolor="red", ncp=10) +
labs(title="PCA Coverage",
x="Principal Components", y="% of variances")
# additional libraries
library(factoextra)
library(caret)
library(readr)
library(apeglm)
library(EnhancedVolcano)
library(ComplexHeatmap)
library(purrr)
# additional libraries
library(factoextra)
library(caret)
library(readr)
library(apeglm)
library(EnhancedVolcano)
library(ComplexHeatmap)
library(purrr)
install_github("kassambara/factoextra")
install.packages("factoextra")
install.packages("factoextra")
# Perform PCA of the samples using log2 transformed TPM values & making scree plot
res.pca = prcomp(logTPM.df, scale = TRUE)
pca.var.per = round(res.pca$sdev^2/sum(res.pca$sdev^2)*100,1)
fviz_eig(res.pca, addlabels=TRUE, ylim=c(0,100),
geom=c("bar", "line"), barfill="gold",
barcolor="grey", linecolor="red", ncp=10) +
labs(title="PCA Coverage",
x="Principal Components", y="% of variances")
# NEED TO FIX
# getting the transcript-level TPM values
TPM = txi[["abundance"]]
TPM.df = data.frame(TPM)
# Taking log2(TPM+2) transformation (resolves issue with 0s and negatives)
logTPM = log2(TPM+2)
logTPM.df = data.frame(logTPM)
# Perform PCA of the samples using log2 transformed TPM values & making scree plot
res.pca = prcomp(logTPM.df, scale = TRUE)
pca.var.per = round(res.pca$sdev^2/sum(res.pca$sdev^2)*100,1)
fviz_eig(res.pca, addlabels=TRUE, ylim=c(0,100),
geom=c("bar", "line"), barfill="gold",
barcolor="grey", linecolor="red", ncp=10) +
labs(title="PCA Coverage",
x="Principal Components", y="% of variances")
1.000000e-03
View(knn)
summary(knn)
knn
logistic
lr
ridge
knn[["besttune"]]
knn[["bestTune"]]
### Your code here
knn[["results"]][knn[["results"]]$k == knn[["bestTune"]]]
lr[["results"]]
ridge[["results"]]
lasso[["results"]]
elastic[["results"]]
rf[["results"]]
svm[["results"]]
### Your code here
knn[["results"]][knn[["results"]]$k == knn[["bestTune"]], ]
lr[["results"]]
ridge[["results"]]
lasso[["results"]]
elastic[["results"]]
rf[["results"]]
svm[["results"]]
### Your code here
knn[["results"]][, knn[["results"]]$k == knn[["bestTune"]]]
lr[["results"]]
ridge[["results"]]
lasso[["results"]]
elastic[["results"]]
rf[["results"]]
svm[["results"]]
### Your code here
knn[["results"]]$k
lr[["results"]]
ridge[["results"]]
lasso[["results"]]
elastic[["results"]]
rf[["results"]]
svm[["results"]]
### Your code here
knn[["results"]][knn[["results"]]$k == knn[["bestTune"]],]
lr[["results"]]
ridge[["results"]]
lasso[["results"]]
elastic[["results"]]
rf[["results"]]
svm[["results"]]
View(ridge)
### Your code here
# KNN summary
knn_best = knn[["bestTune"]]
knn_results = knn[["results"]]
knn_results[knn_results$k == knn_best, ]
lr[["results"]]
ridge[["results"]]
lasso[["results"]]
elastic[["results"]]
rf[["results"]]
svm[["results"]]
### Your code here
# KNN summary
knn_best = knn[["bestTune"]]
knn_results = knn[["results"]]
knn_results[knn_results$k == knn_best$k, ]
lr[["results"]]
ridge[["results"]]
lasso[["results"]]
elastic[["results"]]
rf[["results"]]
svm[["results"]]
### Your code here
# KNN summary
knn_best = knn[["bestTune"]]
knn_results = knn[["results"]]
knn_results[knn_results$k == knn_best$k, ]
# Logistic summary
lr[["results"]]
# Ridge summary
ridge_best = ridge[["bestTune"]]
ridge_results = ridge[["results"]]
ridge_results[ridge_results$lambda == knn_best$lambda, ]
lasso[["results"]]
elastic[["results"]]
rf[["results"]]
svm[["results"]]
### Your code here
# KNN summary
knn_best = knn[["bestTune"]]
knn_results = knn[["results"]]
knn_results[knn_results$k == knn_best$k, ]
# Logistic summary
lr[["results"]]
# Ridge summary
ridge_best = ridge[["bestTune"]]
ridge_results = ridge[["results"]]
ridge_results[ridge_results$lambda == ridge_best$lambda, ]
lasso[["results"]]
elastic[["results"]]
rf[["results"]]
svm[["results"]]
### Your code here
# KNN summary
knn_best = knn[["bestTune"]]
knn_results = knn[["results"]]
knn_results[knn_results$k == knn_best$k, ]
# Logistic summary
lr[["results"]]
# Ridge summary
ridge_best = ridge[["bestTune"]]
ridge_results = ridge[["results"]]
ridge_results[ridge_results$lambda == ridge_best$lambda, ]
# Lasso summary
lasso_best = lasso[["bestTune"]]
lasso_results = lasso[["results"]]
lasso_results[lasso_results$lambda == lasso_best$lambda, ]
elastic[["results"]]
rf[["results"]]
svm[["results"]]
View(elastic)
### Your code here
# KNN summary
knn_best = knn[["bestTune"]]
knn_results = knn[["results"]]
knn_results[knn_results$k == knn_best$k, ]
# Logistic summary
lr[["results"]]
# Ridge summary
ridge_best = ridge[["bestTune"]]
ridge_results = ridge[["results"]]
ridge_results[ridge_results$lambda == ridge_best$lambda, ]
# Lasso summary
lasso_best = lasso[["bestTune"]]
lasso_results = lasso[["results"]]
lasso_results[lasso_results$lambda == lasso_best$lambda, ]
# Elastic summary
elastic_best = elastic[["bestTune"]]
elastic_results = elastic[["results"]]
elastic_results[elastic_results$lambda == elastic_best$lambda &
elastic_results$alpha == elastic_best$alpha, ]
elastic[["results"]]
rf[["results"]]
svm[["results"]]
elastic
rf
### Your code here
# KNN summary
knn_best = knn[["bestTune"]]
knn_results = knn[["results"]]
knn_results[knn_results$k == knn_best$k, ]
# Logistic summary
lr[["results"]]
# Ridge summary
ridge_best = ridge[["bestTune"]]
ridge_results = ridge[["results"]]
ridge_results[ridge_results$lambda == ridge_best$lambda, ]
# Lasso summary
lasso_best = lasso[["bestTune"]]
lasso_results = lasso[["results"]]
lasso_results[lasso_results$lambda == lasso_best$lambda, ]
# Elastic summary
elastic_best = elastic[["bestTune"]]
elastic_results = elastic[["results"]]
elastic_results[elastic_results$lambda == elastic_best$lambda &
elastic_results$alpha == elastic_best$alpha, ]
# Random Forest summary
rf_best = rf[["bestTune"]]
rf_results = rf[["results"]]
rf_results[rf_results$mtry == rf_best$mtry,]
svm[["results"]]
### Your code here
# KNN summary
knn_best = knn[["bestTune"]]
knn_results = knn[["results"]]
knn_results[knn_results$k == knn_best$k, ]
# Logistic summary
lr[["results"]]
# Ridge summary
ridge_best = ridge[["bestTune"]]
ridge_results = ridge[["results"]]
ridge_results[ridge_results$lambda == ridge_best$lambda, ]
# Lasso summary
lasso_best = lasso[["bestTune"]]
lasso_results = lasso[["results"]]
lasso_results[lasso_results$lambda == lasso_best$lambda, ]
# Elastic summary
elastic_best = elastic[["bestTune"]]
elastic_results = elastic[["results"]]
elastic_results[elastic_results$lambda == elastic_best$lambda &
elastic_results$alpha == elastic_best$alpha, ]
# Random Forest summary
rf_best = rf[["bestTune"]]
rf_results = rf[["results"]]
rf_results[rf_results$mtry == rf_best$mtry,]
# SVM summary
svm_best = svm[["bestTune"]]
svm_results = svm[["results"]]
svm_results[svm_results$mtry == svm_best$C,]
View(svm)
svm_best
svm_best$C
### Your code here
# KNN summary
knn_best = knn[["bestTune"]]
knn_results = knn[["results"]]
knn_results[knn_results$k == knn_best$k, ]
# Logistic summary
lr[["results"]]
# Ridge summary
ridge_best = ridge[["bestTune"]]
ridge_results = ridge[["results"]]
ridge_results[ridge_results$lambda == ridge_best$lambda, ]
# Lasso summary
lasso_best = lasso[["bestTune"]]
lasso_results = lasso[["results"]]
lasso_results[lasso_results$lambda == lasso_best$lambda, ]
# Elastic summary
elastic_best = elastic[["bestTune"]]
elastic_results = elastic[["results"]]
elastic_results[elastic_results$lambda == elastic_best$lambda &
elastic_results$alpha == elastic_best$alpha, ]
# Random Forest summary
rf_best = rf[["bestTune"]]
rf_results = rf[["results"]]
rf_results[rf_results$mtry == rf_best$mtry,]
# SVM summary
svm_best = svm[["bestTune"]]
svm_results = svm[["results"]]
svm_results[svm_results$C == svm_best$C,]
View(elastic)
elastic[["results"]]
elastic[["finalModel"]]
elastic[["finalModel"]]$beta
elastic$finalModel
coef(coef(elastic$finalModel))
coef(elastic$finalModel)
coef(elastic$finalModel, elastic$bestTune$lambda)
coef(lasso$finalModel, lasso$bestTune$lambda)
coef(lr$finalModel)
### Your code here
lr_coef = coef(lr$finalModel)
ridge_coef = coef(ridge$finalModel, ridge$bestTune$lambda)
lasso_coef = coef(lasso$finalModel, lasso$bestTune$lambda)
elastic_coef = coef(elastic$finalModel, elastic$bestTune$lambda)
View(lasso_coef)
View(lasso_coef)
View(lasso_coef)
lasso_coef[0]
lasso_coef[1]
lr_coef[1]
cbind(lr_coef, ridge_coef)
cbind(lr_coef, ridge_coef, lasso_coef, elastic_coef)
### Your code here
lr_coef = coef(lr$finalModel)
ridge_coef = coef(ridge$finalModel, ridge$bestTune$lambda)
lasso_coef = coef(lasso$finalModel, lasso$bestTune$lambda)
elastic_coef = coef(elastic$finalModel, elastic$bestTune$lambda)
coefs = data.frame(cbind(lr_coef, ridge_coef, lasso_coef, elastic_coef))
### Your code here
lr_coef = coef(lr$finalModel)
ridge_coef = coef(ridge$finalModel, ridge$bestTune$lambda)
lasso_coef = coef(lasso$finalModel, lasso$bestTune$lambda)
elastic_coef = coef(elastic$finalModel, elastic$bestTune$lambda)
coefs = cbind(lr_coef, ridge_coef, lasso_coef, elastic_coef)
rownames(coefs) = c("Logistic", "Ridge", "Lasso", "Elastic")
coef
coefs
as.matrix(coefs)
### Your code here
lr_coef = coef(lr$finalModel)
ridge_coef = coef(ridge$finalModel, ridge$bestTune$lambda)
lasso_coef = coef(lasso$finalModel, lasso$bestTune$lambda)
elastic_coef = coef(elastic$finalModel, elastic$bestTune$lambda)
coefs = data.frame(as.matrix(cbind(lr_coef, ridge_coef, lasso_coef, elastic_coef)))
rownames(coefs) = c("Logistic", "Ridge", "Lasso", "Elastic")
View(coefs)
### Your code here
lr_coef = coef(lr$finalModel)
ridge_coef = coef(ridge$finalModel, ridge$bestTune$lambda)
lasso_coef = coef(lasso$finalModel, lasso$bestTune$lambda)
elastic_coef = coef(elastic$finalModel, elastic$bestTune$lambda)
coefs = data.frame(as.matrix(cbind(lr_coef, ridge_coef, lasso_coef, elastic_coef)))
rowname(coefs) = c("Logistic", "Ridge", "Lasso", "Elastic")
### Your code here
lr_coef = coef(lr$finalModel)
ridge_coef = coef(ridge$finalModel, ridge$bestTune$lambda)
lasso_coef = coef(lasso$finalModel, lasso$bestTune$lambda)
elastic_coef = coef(elastic$finalModel, elastic$bestTune$lambda)
coefs = data.frame(as.matrix(cbind(lr_coef, ridge_coef, lasso_coef, elastic_coef)))
row.name(coefs) = c("Logistic", "Ridge", "Lasso", "Elastic")
### Your code here
lr_coef = coef(lr$finalModel)
ridge_coef = coef(ridge$finalModel, ridge$bestTune$lambda)
lasso_coef = coef(lasso$finalModel, lasso$bestTune$lambda)
elastic_coef = coef(elastic$finalModel, elastic$bestTune$lambda)
coefs = data.frame(as.matrix(cbind(lr_coef, ridge_coef, lasso_coef, elastic_coef)))
row.names(coefs) = c("Logistic", "Ridge", "Lasso", "Elastic")
### Your code here
lr_coef = coef(lr$finalModel)
ridge_coef = coef(ridge$finalModel, ridge$bestTune$lambda)
lasso_coef = coef(lasso$finalModel, lasso$bestTune$lambda)
elastic_coef = coef(elastic$finalModel, elastic$bestTune$lambda)
coefs = data.frame(as.matrix(cbind(lr_coef, ridge_coef, lasso_coef, elastic_coef)))
colnames(coefs) = c("Logistic", "Ridge", "Lasso", "Elastic")
### Your code here
# extracting coefficients from best models
lr_coef = coef(lr$finalModel)
ridge_coef = coef(ridge$finalModel, ridge$bestTune$lambda)
lasso_coef = coef(lasso$finalModel, lasso$bestTune$lambda)
elastic_coef = coef(elastic$finalModel, elastic$bestTune$lambda)
# printing out table of coefficients
coefs = data.frame(as.matrix(cbind(lr_coef, ridge_coef, lasso_coef, elastic_coef)))
colnames(coefs) = c("Logistic", "Ridge", "Lasso", "Elastic")
print(coefs)
1-0.3
0.7/2
predict(res.pca, test_data)
scale(test_data, res.pca$center, res.pca$scale)
scale(test_data, res.pca$center, res.pca$scale) %*% res.pca$rotation
res.pca$center
# read in data
train_label = read.delim("Q2/raw_data2/BRCA_phenotype.txt",
header = TRUE, stringsAsFactors = FALSE, quote = "", sep = "\t")
train_data = read.delim("Q2/raw_data2/BRCA_zscore_data.txt",
header = TRUE, stringsAsFactors = FALSE, quote = "", sep = "\t")
# read in data
train_label = read.delim("Q2/raw_data2/BRCA_phenotype.txt",
header = TRUE, stringsAsFactors = FALSE, quote = "", sep = "\t")
train_data = read.delim("Q2/raw_data2/BRCA_zscore_data.txt",
header = TRUE, stringsAsFactors = FALSE, quote = "", sep = "\t")
